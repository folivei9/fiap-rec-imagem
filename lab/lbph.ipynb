{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA - Inteligencia Articifial e Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VersÃ£o do OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando 100 exemplos de faces com a webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colega de amostras completado\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('classificadores/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Extrator de faces\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Coletar 100 exemplos de um determinado rosto\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Amostra\", frame)\n",
    "        if face_extractor(frame) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            file_name_path = 'imagens/amostras/' + str(count) + '.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "\n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            cv2.imshow('Rosto Normalizado', face)\n",
    "\n",
    "        if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Colega de amostras completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e implementando o modelo utilizando LBPH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo treinado com sucesso.\n",
      "(0, 26.21837906791346)\n",
      "(0, 26.01226500080059)\n",
      "(0, 26.15320770226117)\n",
      "(0, 25.82950986972437)\n",
      "(0, 25.687915936542108)\n",
      "(0, 65.97203453335604)\n",
      "(0, 25.65365895572332)\n",
      "(0, 26.320117137723344)\n",
      "(0, 26.439663023443917)\n",
      "(0, 26.373328205104965)\n",
      "(0, 26.487702638491907)\n",
      "(0, 27.28011244327341)\n",
      "(0, 26.76045196723702)\n",
      "(0, 27.635849667881505)\n",
      "(0, 27.659454938540925)\n",
      "(0, 27.75635010308859)\n",
      "(0, 27.723251178892895)\n",
      "(0, 29.886743537648364)\n",
      "(0, 28.220384596200656)\n",
      "(0, 27.55076956729598)\n",
      "(0, 28.592503764075836)\n",
      "(0, 26.96921213043621)\n",
      "(0, 28.186490299832073)\n",
      "(0, 28.191863454395904)\n",
      "(0, 27.978336877787353)\n",
      "(0, 28.46973642352464)\n",
      "(0, 27.831419070892427)\n",
      "(0, 28.991489338260248)\n",
      "(0, 28.001549383032714)\n",
      "(0, 28.558036872717995)\n",
      "(0, 27.738714843808395)\n",
      "(0, 28.42091391633472)\n",
      "(0, 28.9337569824534)\n",
      "(0, 27.98129005345317)\n",
      "(0, 28.65438384320057)\n",
      "(0, 28.393783049203694)\n",
      "(0, 28.27190909768392)\n",
      "(0, 29.297872829064545)\n",
      "(0, 28.54691017853322)\n",
      "(0, 27.619179104029964)\n",
      "(0, 31.64525849305558)\n",
      "(0, 32.84351092944438)\n",
      "(0, 33.95870101807323)\n",
      "(0, 34.3962947060686)\n",
      "(0, 34.27050517997879)\n",
      "(0, 34.65140740724118)\n",
      "(0, 35.082160105462094)\n",
      "(0, 35.445552906504886)\n",
      "(0, 34.76530304391494)\n",
      "(0, 36.584213772879934)\n",
      "(0, 38.041098351925825)\n",
      "(0, 38.56673797206779)\n",
      "(0, 37.97094883358081)\n",
      "(0, 36.734642532655656)\n",
      "(0, 35.348943544399575)\n",
      "(0, 32.766748691524036)\n",
      "(0, 29.89962706770046)\n",
      "(0, 29.08685130384538)\n",
      "(0, 28.406080706611224)\n",
      "(0, 27.885369530755316)\n",
      "(0, 28.77162589439519)\n",
      "(0, 29.621479961566965)\n",
      "(0, 31.18772735576223)\n",
      "(0, 33.41234565567073)\n",
      "(0, 35.45648474244797)\n",
      "(0, 39.07465365510741)\n",
      "(0, 39.31247504924107)\n",
      "(0, 42.106602637833404)\n",
      "(0, 43.021196541059844)\n",
      "(0, 43.82974722591489)\n",
      "(0, 44.57874518103014)\n",
      "(0, 43.09331123277099)\n",
      "(0, 43.30504286129075)\n",
      "(0, 41.2411571861445)\n",
      "(0, 39.94188630840668)\n",
      "(0, 36.20510639581682)\n",
      "(0, 32.790428487022325)\n",
      "(0, 31.642623032724014)\n",
      "(0, 32.13915085584046)\n",
      "(0, 30.37354651969933)\n",
      "(0, 28.924019525677988)\n",
      "(0, 29.8758514689412)\n",
      "(0, 30.913994104751655)\n",
      "(0, 31.25234153920263)\n",
      "(0, 32.06843806713778)\n",
      "(0, 32.57319582711517)\n",
      "(0, 32.343462308651546)\n",
      "(0, 31.888957566033195)\n",
      "(0, 31.93729884987623)\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "#TREINANDO O MODELO\n",
    "#-----------------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Carregando exemplos de arquivos previamente coletados\n",
    "data_path = 'imagens/amostras/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "training_data, labels = [], []\n",
    "\n",
    "# Lendo as imagens e associando a um label\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    training_data.append(images)\n",
    "    labels.append(0)\n",
    "\n",
    "# Criando uma matriz da lista de labels\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "# Treinamento do modelo\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(training_data, np.array(labels))\n",
    "\n",
    "print(\"Modelo treinado com sucesso.\")\n",
    "\n",
    "persons = {0: \"Fernando\"}\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "#IMPLEMENTANDO O MODELO\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "def face_detector(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.1, 5)\n",
    "    if faces is ():\n",
    "        return img, [], 0, 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi, x, y\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face, x, y = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        print(results)\n",
    "        \n",
    "        if x > 0:\n",
    "            display_string = \"Dist. \" + str(int(results[1])) + ' ' + persons[results[0]] \n",
    "            cv2.putText(image, display_string, (x, y-20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "        if int(results[1]) < 40:\n",
    "            cv2.putText(image, \"Reconhecido com sucesso\", (x, y-50), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "        else:\n",
    "            cv2.putText(image, \"Nao reconhecido\", (250, 450), cv2.FONT_HERSHEY_DUPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "    except:\n",
    "        cv2.putText(image, \"Rosto nao identificado\", (220, 120) , cv2.FONT_HERSHEY_DUPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Nao reconhecido\", (250, 450), cv2.FONT_HERSHEY_DUPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
